# Calidad de los Datos

Uno de los principios más antiguos de la informática nos dice "entra basura, sale basura" y se refiere al hecho de que si un programa recibe como entrada datos incorrectos o sin sentido en la salida tendremos lo mismo. Este principio también se aplica a la ciencia de datos pues el éxito del proceso depende de la validez de los datos que analizamos. Uno de los mayores retos de la minería de datos es la recolección y limpieza de los datos. Para darnos una idea de la complejidad de estas tareas vamos a considerar el desarrollo de un [Observatorio de Lesiones](http://conapra.salud.gob.mx/Interior/Observatorio_Nacional_Lesiones.html). El objetivo de estos sistemas según la secretaría de salud es "... generar datos y evidencia científica para la prevención de lesiones ocasionadas por accidentes viales”. Es muy importante para este tipo de sistemas contar con información confiable y completa sobre los accidentes de tráfico, pero como veremos esto no es nada fácil. Para empezar, atender un accidente involucra varias organizaciones: cruz roja, paramédicos, policía, hospitales, call-centers de emergencia, rescatistas, agencias de seguros entre otras. Por otro lado, se involucran transeúntes, vehículos, pasajeros, edificios, reporteros etc. Para obtener información sobre lo sucedido normalmente se debe  entrevistar a testigos e involucrados, desde aquí  empieza el problema, ya que cada persona tiene su versión de los hechos, puede cambiarla o estar incapacitadas para dar la información. Cada dependencia tiene la urgencia de recolectar información para cumplir con sus propósitos particulares y cada una tiene su versión parcial de los hechos. El accidente puede relacionarse con otros eventos posteriores, por ejemplo una persona puede sufrir secuelas del accidente El evento en sí es complejo, por ejemplo una persona puede sufrir secuelas del accidente mucho tiempo después. La tarea de integrar los datos requiere la cooperación entre distintas dependencias lo cual nos da un primer golpe de realidad: En muchas ocasiones no estará en nuestras manos la calidad de los datos, ni tendremos control sobre la fuente de los mismos. Por lo anterior la minería de datos se enfoca solamente en dos tareas básicas [ref Tan, Kumar]: (1) la detección y corrección de problemas en los datos y (2) la utilización de algoritmos que puedan tolerar datos de mala calidad.

Al recolectar datos de otras fuentes, primero debemos realizar una tarea de "limpieza de datos". Esta limpieza es necesaria para asegurar la calidad de los datos. Se considera que los datos son de buena calidad si son consistentes y cumplen con su propósito. Por ejemplo, una tarea del observatorio de accidentes de tráfico podría ser el optimizar la ubicación de estaciones de rescate. Entre los datos requeridos para este objetivo se debe incluir la ubicación exacta de los accidentes. Aquellos registros que solo incluyan la zona o la calle del accidente no serían útiles para la tarea en cuestión, pero podrían ser de utilidad para otros propósitos.

A continuación discutiremos algunos problemas que afectan la calidad de los datos:

### Fuentes de datos poco confiables

En muchos casos la colección de datos no se realiza con el objetivo de realizar una investigación científica por lo que la autenticidad y calidad de los datos puede variar. Jianzheng Liu et al.(2015) identifican tres diferencias entre la recolección de datos realizada por una empresa comercial y una institución de investigación científica:

1. Las empresas no adoptan procedimientos científicos de recolección de datos como muestreos aleatorios o procedimientos para evitar el sesgo y otros problemas. Las empresas recolectan información con el objetivo de producir ganancias no para hacer ciencia. Normalmente el muestreo de datos se realiza sobre la población objetivo de las empresas y no sobre el público en general.

2. Los métodos de recolección de datos no son públicos y pueden cambiar sin aviso alguno.

3. Las plataformas comerciales no se pueden hacer responsables de la autenticidad ni la validez de los datos que colectan. Por ejemplo, al utilizar datos de una red social como Twitter debemos considerar a las cuentas de *Bots*, usuarios pagados para producir contenido, anuncios y publicaciones tipo *Spam*.

Como podemos ver, la calidad de los datos no solo se refiere a la medición o la captura en sí, también debemos tener en cuenta el procedimiento utilizado en la recolección.

### Errores de medición y recolección de datos

Llamamos errores de medición a aquellos problemas que suceden en el proceso de medición o captura. En el caso de los atributos continuos, llamamos error a la diferencia numérica entre el valor real y el medido. Un error de medición se puede dar también cuando un sensor no tiene la precisión adecuada e incluso cuando la medida se trunca al asignarse a una variable que no tiene la escala o precisión adecuada.

Un error de recolección de datos se refiere a problemas de captura al nivel de objetos o atributos. Por ejemplo, cuando omitimos el valor de un atributo o capturamos un objeto en una categoría equivocada.  



### Valores nulos

## Valores atípicos

### Inconsistencias


### Valores Duplicados

### Datos con Ruido
En algunas publicaciones llaman *ruido* a las imperfecciones en los datos. Tal como sucede cuando hay interferencia en la señal de radio y escuchamos la música con ruido. El ruido en los datos son precisamente los errores de medición, recolección, valores atípicos e inconsistencias en los datos. En ocasiones es necesario perturbar o agregar ruido a los datos ya sea para conservar la privacidad de la fuente o para probar que tan robusto es un algoritmo. Para agregar ruido a un conjunto de datos normalmente se agregan componentes aleatorios. Por ejemplo, se pueden agregar nuevos objetos con atributos aleatorios o


Evento-Transito
  ciudad
  latitud,
  longitud,
  lugar
  tipo_incidente,
  limite_velocidad
  condicion_vial
  fecha_hora
  condicion_luz
  hra_llamada = models.TimeField((u"Hora de llamada: "), blank=True)
  hra_escena = models.TimeField((u"Hora en la escena:"), blank=True)
  conductor_alcoholizado = models.IntegerField()
  num_lesionados = models.IntegerField()


Evento-Ambulancia    
edad = models.IntegerField(null=True, blank=True)
sexo = models.IntegerField(choices=sexo_choices, null=True, blank=True)
rol = models.ForeignKey(rol_persona)
gravedad_lesion = models.ForeignKey(gravedad_lesion)
num_ambulancia = models.CharField(max_length=2, null=True, blank=True)
operador = models.CharField(max_length=50, null=True, blank=True)
fecha_hora  
lugar = models.ForeignKey(evento)
vehiculo = models.ForeignKey(vehiculo, null=True, blank=True)
muerte_escena = models.ForeignKey(muerte_escena)
prioridad = models.ForeignKey(prioridad)

Evento-Vehiculo
num_ocupantes = models.IntegerField()
modelo = models.ForeignKey(modelo)
marca = models.ForeignKey(marca)
año = models.IntegerField()
vin = models.IntegerField()
num_muertos = models.IntegerField()
conductor_alcoholizado = models.BooleanField()
num_lesionados = models.PositiveIntegerField()
