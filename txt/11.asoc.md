# Análisis de Asociaciones

La tarea de la minería de datos es extraer de manera eficiente patrones útiles
de grandes bases de datos. La extracción de reglas de asociación surge con el
fin descubrir patrones de compra interesantes minando las transacciones de
compra en tiendas al menudeo [@hilderman1999knowledge]. Debido a su principal
aplicación también se le conoce como *Market Basket Analysis* y fue propuesta
inicialmente en [@agrawal1993mining]. Las reglas que se extraen tienen que ver con los articulos que se compran en una transacción y tienen una forma de implicación, por ejemplo:

$\{Skittles, Donas \} \implies \{ Diet Coke \}$ 

La regla sugiere que las personas que compran *Skittles* y Donas también
compran *Diet Coke*. Las reglas incluyen un porcentaje de transacciones que
cumplen con ella. Este conocimiento puede ser utilizado por los empresarios
para la toma de decisiones. Por ejemplo, surtir más un producto, hacer
promociones o ver el impacto que tendría descontinuar algún articulo.

## Definición formal del problema

El problema se ha definido formalmente por @agrawal1993mining: Sea $I = \{i_1,
i_2,\dots,i_m\}$ un conjunto de $m$ atributos binarios a los que llamaremos
*ítems*. Sea $T=\{t_1,t_2,\dots, t_m \}$ un conjunto de $m$ transacciones al
que llamaremos *database*. Cada transacción $t$ es representada por un vector
binario, donde $t[k] = 1$ si en la transacción se compró el ítem $i_k$ en caso
contrario $t[k] = 0$. Sea $X$ un conjunto de ítems en $I$. Decimos que que la
transacción $t$ *satisface* a $X$, si para todos los ítems $I_k$ en $X$, se
cumple que $t[k] = 1$, es decir se compraron todos los ítems $X$. Una *regla de
asociación* se define como una implicación $X \implies I_j$. Como podemos ver
originalmente se consideraba en el consecuente solo un ítem, actualmente se
considera a un conjunto de ítems. Los conjuntos $X$ e $I$ no tienen ítems en
común y a ambos se les denomina *itemsets*, conjuntos de ítems.

También se definen dos restricciones que deben cumplir las reglas, el soporte y
la confianza.

* **Soporte** el soporte indica la frecuencia en la que las transacciones $T$
 incluyen a cierto ítemset. 

 $\mathrm{supp}(X) = \frac{|\{t \in T; X \subseteq t\}|}{|T|}$

* **Confianza** indica que tan frecuentemente se cumple cierta regla $X \implies I$ en $T$

$\mathrm{conf}(X \Rightarrow I) = \mathrm{supp}(X \cup I) / \mathrm{supp}(I)$

Estas restricciones tienen como objetivo el filtrar aquellas reglas que no sean interesantes o que sean poco comunes. El soporte y la confianza se proporcionan al algoritmo como un umbrales mínimos que deben cumplir las reglas que resulten de la búsqueda.

El proceso de minado de reglas puede resumirse en dos pasos:

1. Encontrar todos los conjuntos de artículos que tengan la frecuencia mínima indicada por el umbral    de soporte.

2. A partir de los conjuntos de artículos encontrados en el primer paso, se generan reglas que cumplan  con la restricción de confianza mínima.

Las dos tareas se detallan en las siguientes secciones.

## Generación de conjuntos de artículos frecuentes

![Rejilla de ítemset](../img/itemset-1.png){ width=50% }

Para enumerar todos los posibles ítemsets se emplea una rejilla. Como ejemplo en la figura se muestra la rejilla para el conjunto de ítems $I = \{a, b, c,\}$. Al incrementar el número de ítems el número de ítemsets se incrementa exponencialmente. Evaluar a fuerza bruta el soporte de cada una de las transacciones en $T$ tiene un costo computacional muy alto ya que se tiene que comparar cada ítemset candidato con todas las transacciones. La técnica *Apriori* es utilizada para reducir la complejidad computacional.

### El principio Apriori

Para reducir el número de ítemsets candidatos a evaluar, se utiliza el principio Apriori : 

*Si un ítemset ocurre de manera frecuente, entonces todos sus subconjuntos también son frecuentes* 
Esto se ilustra en la figura, donde suponemos que el ítemset {b, c} es frecuente, también los serán {b} y {c}. 

![Rejilla de ítemset](../img/itemset-3.png){ width=50% }

Por otro lado, si el ítemset {a} es infrecuente los super conjuntos también lo serán. Esto permite eliminar de la rejilla aquellos ítemsets bajo el ítemset infrecuente. Por ejemplo en la Figura, si hay evidencia de que el ítemset {a} es infrecuente, también los serán {a, b}, {a, c} y {a, b, c} por lo que no hay necesidad de evaluarlos. El algoritmo de generación de ítemsets Apriori se aprovecha de este principio. Se empieza en la raíz de la rejilla evaluando el soporte de los ítemsets con un solo elemento y solo continúa evaluando los ítemsets que incluyan solo a los ítems con el soporte necesario.

![Rejilla de ítemset](../img/itemset-2.png){ width=50% }

## Generación de reglas

Una vez que tenemos los ítemsets frecuentes, podemos empezar a generar reglas.
Tomemos un itemset $Y$ con $k$ ítems, podríamos generar $2^K - 2$ reglas de
asociación sin considerar aquellas reglas con ítemsets nulos. Para generar una
regla, basta dividir a $Y$ en dos conjuntos no nulos: $X$ y $Y-X$. Obtenemos la
regla $X \implies Y-X$, ahora solo tenemos que evaluar si cumple con la
restricción de confianza mínima.

Para calcular la confianza, no es necesario evaluar en todas las transacciones,
ya que la función de confianza se calcula utilizando el soporte de los ítemsets
y esto ya lo calculamos en el paso anterior.

## Representación compacta de conjuntos de artículos frecuentes

Con el objetivo práctico de reducir el espacio de almacenamiento, se han propuesto técnicas para representar de una manera compacta a la rejilla de artículos frecuentes. Veamos una técnica basada en el concepto de artículos frecuentes máximos. 

Un ítemset de frecuencia máximo es aquel que en la rejilla no tiene un superconjunto inmediato superior que también sea frecuente. En la figura se presenta una rejilla con tres con ítemsets de frecuencia máximos $\{a, d\}$, $\{a, c, e\}$, $\{b, c, d, e\}$. Solo con estos ítemsets podemos derivar los ítemsets frecuentes restantes ya que están incluido (son subconjuntos) de los mismos.

![Rejilla de ítemset @tan2007introduction ](../img/lattice.png)

## El algiritmo FP-Growth

Uno de los algoritmos más utilizados para el minado de reglas de asociación es el algoritmo FP-Growth[han2000mining]. El algoritmo aborda el problema de generación de ítemsets de una manera muy distinta a la estrategía utilizada por *Apriori*. El algoritmo propone el uso de una estructura compacta llamada FP-tree de donde se extraen directamente los ítemsets frecuentes. El algoritmo recorre la base de datos de transacciones una primera vez agregando solo las transacciones frecuentes una tabla de encabezado, en una segunda pasada inserta las transacciones como una ruta del FP-tree. Cuando los ítems se van repitiendo las rutas se traslapan en el árbol, con lo cual se almacena de una manera más compacta, incluso puede almacenarse en la memoria. Los ítemsets que no tienen la frecuencia mínima no son almacenados. 

**Ejemplo** 

El siguiente ejercicio se incluye en [@han2000mining]:

| Tid| Ítems                   | Ítems frecuentes (ordenados)  |
|----|-------------------------|-------------------------------|
| 1  | f, a, c, d, g, i, m, p  | f, c, a, m, p                 |
| 2  | a, b, c, f, l, m; o     | f, c, a, b, m                 |
| 3  | b, f, h, j, o,          | f, b|
| 4  | b, c, k, s, p,          | c, b, p|
| 5  | a, f, c, e, l, p, m, n  | f, c, a, m, p  |

![Ejemplo de F-Tree @han2000mining ](../img/fpgrowth.png) { }