
# Pandas

El análisis de datos comúnmente se realiza sobre datos que se encuentran organizados en forma de tablas. Probablemente ya haz utilizado datos organizados de esta manera al utilizar una hoja de cálculo o tablas en servidores de bases de datos relacionales como Oracle, PostgreSQL o SQLServer. En python incluso podemos almacenar los datos de una tabla utilizando un arreglo de tuplas. 

## Otras opciones 

### ¿Por que no utilizamos tablas de SQL?
Los sistemas de bases de datos tienen como objetivo almacenar grandes
cantidades de datos y al mismo tiempo nos permiten realizar un gran
número de transacciones de manera concurrente. Dicho de otra manera
los servidores nos permiten realizar la parte operativa de una
empresa, vender boletos para conciertos, inscribir alumnos, llevar el
control de un almacén, procesar los pedidos en una tienda en línea,
etc. Además de esto cuentan con un lenguaje de alto nivel para
definir, manipular y consultar a los datos. El lenguaje estándar SQL
ha sido el preferido por los desarrolladores para consultar de una
manera muy flexible a los datos relacionales. El problema que tenemos
en estos sistemas es que su objetivo principal no es el analizar los
datos, estos sistemas nos permiten más bien implementar sistemas que
necesitan manipular datos en-línea para funcionar. Por otro lado, para
hacer nuestro análisis, podemos utilizar perfectamente datos que estén
fuera de línea, datos históricos o incluso datos ficticios. Mucho del
*overhead* de un servidor de bases de datos se tiene precisamente por
que estos deben ser capaces de modificar las estructuras de las
tablas, hacer modificaciones a objetos, mantener la consistencia,
controlar el acceso y muchas otras operaciones. Todo en línea. Al no
tener estos requisitos podemos operar con estructuras diseñadas
precisamente para el análisis de datos.  Dicho esto, algunos sistemas
de bases de datos han agregado la funcionalidad necesaria para
realizar el tipo de análisis que veremos, pero esto no es todavía el
estándar. Los sistemas de bases de datos nos pueden servir para
almacenar los datos que utilizaremos en el análisis y realizar algunas
consultas con SQL. Podemos utilizar también la biblioteca SQLite para
almacenar bitácoras, intercambiar información con otros sistemas o
como parte del preprocesamiento.

### ¿Por que no utilizamos NoSQL?
Últimamente se han propuesto gestores de datos que aunque no siguen el modelo relacional nos permiten hacer cierto tipo de consultas de una manera mucho más eficiente. Por ejemplo, los almacenes clave-valor (key-value) pueden recuperar bastante rápido los datos por medio de su clave; pero el lenguaje de consulta, si es que lo hay, no es muy flexible. Son muy buenos para recuperar muy rápido un documento html o un objeto con solo especificar su clave, pero no podemos hacer consultas *ad-hoc* como "recupera aquellos productos que tengan ventas superiores al promedio en las tiendas de California o Arizona, siempre que no sean del departamento de electrónica". Estos sistemas nos pueden servir sobre todo como memoria cache o memoria compartida para realizar operaciones en paralelo.

### ¿Por que no utilizamos Data Warehouse?
Las técnicas de Almacenes de Datos (Data Warehouse) nos permiten realizar de una manera muy sencilla consultas *tipo cubo* sobre bases de datos relacionales.
Aunque las consultas permiten a los ejecutivos tomar decisiones y tener una buena idea de lo que sucede en la empresa, su objetivo no es el de extraer patrones de los datos. Sin embargo el objetivo general y el diseño de los Almacenes de Datos tiene algunas cosas en común con el proceso de KDD. Ambos trabajan con datos históricos y requieren de un proceso previo de extracción de los datos al cual se le conoce como ETL (Extract, Transform and Load) o   Extraer, Transformar y Cargar). El proceso de ETL permite a las empresas extraer datos desde diferentes fuentes, cambiar de formato  y limpiarlos con el objetivo de  cargarlos en el almacén de datos.

### ¿Por que no utilizamos Hoja de Cálculo?
De hecho las hojas de cálculo son una herramienta aceptable para realizar análisis de datos. Muchos analistas utilizan hojas de calculo como herramienta principal. No se requiere tener un amplío conocimiento de programación para sacarles provecho y pueden complementares con otras herramientas por ejemplo con sistemas de bases de datos. Los programadores normalmente preferimos tener un control total sobre el proceso de KDD y nos gusta poder integrar fácilmente nuestro código en distintas aplicaciones, por lo que preferimos la flexibilidad que nos brinda un lenguaje de propósito general.

### Pandas

Pandas es una biblioteca código abierto en Python la cual nos permite
trabajar de una manera sencilla con datos que tienen una estructura de
tabla. La biblioteca se ha diseñado con el objetivo específico de
brindarnos una estructura de datos rápida y flexible para el análisis
de datos. Según
su [documentación](http://pandas.pydata.org/pandas-docs/stable/)
pandas nos permite operar con distintos tipos de datos: 

* Tablas con distintos tipos de atributos (heterogéneos).
* Datos de series de tiempo, con o sin orden
* Matrices homogéneas o heterogéneas.

En pandas se implementan dos estructuras principales: Series y DataFrame. Series nos permite trabajar con datos de una dimensión precisamente como las series de tiempo. Por otro lado DataFrame nos sirve aquellos datos que tienen una estructura de tabla o matriz. En esta sección nos enfocaremos en el DataFrame ya que nos interesa trabajar con Tablas.

### DataFrame 

Vamos a utilizar un DataFrame para almacenar el conjunto de datos conocido como [Auto MPG](https://archive.ics.uci.edu/ml/datasets/Auto+MPG). Los objetos del conjunto de datos tienen los siguientes atributos:

|  nombre        | tipo     | medida     |  descripción             |
|----------------|----------| -----------|--------------------------|
|  mpg           | continuo | razón      | millas por galón         | 
|  cylinders     | discreto | ordinal    | número de cilindros      | 
|  displacement  | continuo | razón      | desplazamiento           | 
|  horsepower    | continuo | razón      | caballos de fuerza       | 
|  weight        | continuo | razón      | peso en libras US        | 
|  acceleration  | continuo | razón      | aceleración              | 
|  model_year    | discreto | razón      | año de fabricación       | 
|  origin        | discreto | categórico | origen                   | 
|  car_name      | cadena   | categórico | nombre único del auto    | 

El objetivo de este conjunto de datos es el de predecir el consumo de combustible en millas por galón a partir de ocho atributos de los automóviles.

Como primer paso vamos a descargar el conjunto de datos del [repositorio](https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/) de una universidad de California Irvine. El archivo se llama auto-mpg.data. Al abrir el archivo en un editor de texto vemos que está separado por espacios y faltan algunos valores. Veamos un fragmento:

```
11.0   8   350.0      180.0      3664.      11.0   73  1	"oldsmobile omega"
20.0   6   198.0      95.00      3102.      16.5   74  1	"plymouth duster"
21.0   6   200.0      ?          2875.      17.0   74  1	"ford maverick"
```

  
